# Sign Language Detection

As a means of communication for individuals with hearing
impairments, sign language plays a pivotal role in facilitating interpersonal interaction and understanding 
the world around them. Through the use of gestures, facial expressions, and specific signs, 
individuals using sign language have the opportunity to express their thoughts, feelings, and 
ideas in the same way as those who use verbal language. However, the development of 
technological solutions that enable automated detection and recognition of sign language 
poses a challenging research area. In this context, computer vision and machine learning 
techniques, including the Random Forest algorithm and the MediaPipe library, have been 
employed to develop a system for real-time sign language detection and recognition. The 
Random Forest algorithm serves as a key tool for sign classification, while the MediaPipe library 
detects key points of the body and hands in real-time. Combining these 
techniques opens new possibilities for improving communication and interaction for 
individuals with hearing impairments. For this research, a dataset consisting of 
990 video recordings, encompassing commonly used words and expressions in Serbian. 
This dataset is essential for training and testing the developed sign language detection 
and recognition model. Our results show that the system in this work achieves performances up to 
97.97 % accuracy on the given dataset.

## Dataset

The dataset is a collection of hand gesture and expression videos captured using a webcam and processed using the OpenCV and Mediapipe libraries. It consists of 33 classes, each representing a different hand gesture or expression.
[Dataset on Kaggle](https://www.kaggle.com/datasets/alpesh98/serbian-sign-language-dataset)

## Real-Time Testing Results


[1_Ezpic4Hz.webm](https://github.com/alpesh24/sign-language-detection/assets/48263828/e56b3d20-8f3e-47ad-9300-f1d62542b0fd)
